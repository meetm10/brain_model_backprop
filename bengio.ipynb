{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Neuron_U:    \n",
    "#     def __init__(self,T):        \n",
    "#     def simulate(self,spike_train,I,sigma,epsilon):\n",
    "#         Vthresh = 1\n",
    "#         Vspike = 0.5        \n",
    "#         hidden_layer[0]['soma'] = hidden_layer[0]['soma'] + (-gLK*hidden_layer[0]['soma'])+gB*(hidden_layer[0]['basal'] - hidden_layer[0]['soma']) + gA(hidden_layer[0]['apical'] - hidden_layer[0]['soma']) + (sigma*epsilon)\n",
    "#         inter[0]['soma'] = inter[0]['soma'] + ((-gLK*inter[0]['soma']) + gD(inter[0]['basal'] - inter[0]['soma']) + I['inter'] + (sigma*epsilon)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Neuron_V:    \n",
    "#     def __init__(self,T):\n",
    "        \n",
    "#     def simulate(self,spike_train,I,sigma,epsilon):\n",
    "#         Vthresh = 1\n",
    "#         Vspike = 0.5        \n",
    "        \n",
    "#         hidden_layer[0]['basal'] = weight_PP[0]*phi(input_layer['soma'])\n",
    "#         hidden_layer[0]['apical'] = weight_PP[1]*phi(hidden_layer[1]['soma'])+weight_PI[0](inter_layer[0]['soma'])\n",
    "#         inter_layer[0]['basal'] =  weight_IP[0]*phi(hidden_layer[0]['soma'])\n",
    "        \n",
    "#         hidden_layer[1]['basal'] = weight_PP[1]*phi(hidden_layer[1]['soma'])\n",
    "#         hidden_layer[1]['apical'] = weight_PP[2]*phi(output_layer['soma'])+weight_PI[1](inter_layer[1]['soma'])\n",
    "#         inter_layer[1]['basal'] =  weight_IP[1]*phi(hidden_layer[1]['soma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def spiketocurrent(spike_train):\n",
    "#     current = 0\n",
    "#     for i in range(len(spike_train)):\n",
    "#         if(spike_train[i] == 1):\n",
    "#             current+=1\n",
    "#         else:\n",
    "#             current = current*(exp(-1))\n",
    "#     return current        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reinitialize_spike(spike_trains,num_of_hidden_layers,T):\n",
    "#     for i in range(784):\n",
    "#         spikes = [0 for j in range(T)]\n",
    "#     spike_trains['input'] = spikes\n",
    "#     for k in range(num_of_hidden_layers):\n",
    "#         for i in range(500):\n",
    "#             spikes = [0 for j in range(T)]\n",
    "#         spike_trains[k] = spikes\n",
    "#     for i in range(10):\n",
    "#         spikes = [0 for j in range(T)]\n",
    "#     spike_trains['output'] = spikes   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_to_current(data):\n",
    "    '''\n",
    "    Takes input as array or array of arrays\n",
    "    Maps 0 as current value 2 and 1 as current value 12\n",
    "    '''\n",
    "    for i,d in enumerate(data):\n",
    "        data[i][data[i]>0] = 12\n",
    "        data[i][data[i]<1] = 2\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_mp(layer,I,epsilon,sigma=0.1,gLK=0.1,gB=1,gA=0.8,gD=1):\n",
    "    if layer == 0:\n",
    "        hidden_layer[layer]['basal'] = np.matmul(weights_PP[layer],phi(input_layer['soma']))\n",
    "    else:\n",
    "        hidden_layer[layer]['basal'] = np.matmul(weights_PP[layer],phi(hidden_layer[0]['soma']))\n",
    "    hidden_layer[layer]['soma'] = hidden_layer[layer]['soma'] + (-gLK*hidden_layer[layer]['soma'])+gB*(hidden_layer[layer]['basal'] - hidden_layer[layer]['soma']) + gA*(hidden_layer[layer]['apical'] - hidden_layer[layer]['soma']) + (sigma*epsilon)\n",
    "    inter_layer[layer]['basal'] = weights_IP[layer]*phi(hidden_layer[layer]['soma'])\n",
    "#     inter[layer]['soma'] = inter[layer]['soma'] + ((-gLK*inter[layer]['soma']) + gD(inter[layer]['basal'] - inter[layer]['soma']) + I + (sigma*epsilon)) \n",
    "    inter_layer[layer]['soma'] = inter_layer[layer]['soma'] + ((-gLK*inter_layer[layer]['soma']) + gD*(inter_layer[layer]['basal'] - inter_layer[layer]['soma']) + I)\n",
    "    if layer==0:\n",
    "        hidden_layer[layer]['apical'] = np.matmul(weights_PP[layer+1],phi(hidden_layer[layer+1]['soma']))+np.transpose(np.matmul(np.transpose(weights_PI[layer]),inter_layer[layer]['soma']))\n",
    "    else:\n",
    "        hidden_layer[layer]['apical'] = np.matmul(np.transpose(weights_PP[layer+1]),phi(output_layer['basal']))+np.transpose(np.matmul(np.transpose(weights_PI[layer]),inter_layer[layer]['soma']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(u):\n",
    "    return 1/(1+np.exp(-u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(num_of_hidden_layers=2,sigma=0.1,gLK=0.1,gB=1,gA=0.8,gD=1):    \n",
    "    V_rest = 0\n",
    "    #layer to layer synaptic weights\n",
    "    eta_PP = np.zeros((3,1))\n",
    "    eta_IP = np.zeros((3,1))\n",
    "    eta_PI = np.zeros((3,1))\n",
    "    hat_hidden_layer = {}\n",
    "    for i in range(num_of_hidden_layers):\n",
    "        hat_hidden_layer[i] = {}\n",
    "        hat_hidden_layer[i]['basal'] = np.zeros((500,1))\n",
    "        hat_hidden_layer[i]['soma'] = np.zeros((500,1))\n",
    "        hat_hidden_layer[i]['apical'] = np.zeros((500,1))\n",
    "    hat_inter_layer = {}\n",
    "    for i in range(num_of_hidden_layers):\n",
    "        hat_inter_layer[i] = {}\n",
    "        hat_inter_layer[i]['basal'] = np.zeros((500,1))\n",
    "        hat_inter_layer[i]['soma'] = np.zeros((500,1))\n",
    "        hat_inter_layer[i]['apical'] = np.zeros((500,1)) \n",
    "    hat_output_layer = {}\n",
    "    hat_output_layer['basal'] = np.zeros((10,1))\n",
    "    hat_output_layer['soma'] = np.zeros((10,1))    \n",
    "    eta_PP[0] = 0.01/(0.3**2)\n",
    "    eta_PP[1] = 0.01/0.3\n",
    "    eta_PP[2] = 0.01\n",
    "    hat_hidden_layer[0]['basal'] = (gB/(gLK + gB + gA))*(hidden_layer[0]['basal'])\n",
    "    weights_PP[0] += eta_PP[0]*np.matmul((phi(hidden_layer[0]['soma']) - phi(hat_hidden_layer[0]['basal'])),np.transpose(input_layer['basal']))\n",
    "    hat_hidden_layer[1]['basal'] = (gB/(gLK + gB + gA))*(hidden_layer[1]['basal'])\n",
    "    weights_PP[1] += eta_PP[1]*np.matmul((phi(hidden_layer[1]['soma']) - phi(hat_hidden_layer[1]['basal'])),np.transpose(hidden_layer[0]['basal']))\n",
    "    hat_output_layer['basal'] = (gB/(gLK + gB + gA))*(output_layer['basal'])\n",
    "    weights_PP[2] += eta_PP[2]*np.matmul((phi(output_layer['soma']) - phi(hat_output_layer['basal'])),np.transpose(hidden_layer[1]['basal']))\n",
    "    \n",
    "    #inter to pyramid synaptic weights\n",
    "    eta_IP[0] = 2*eta_PP[1]\n",
    "    eta_IP[1] = 2*eta_PP[2]\n",
    "    hat_inter_layer[0]['basal'] = (gD/(gLK + gD))*(inter_layer[0]['basal'])\n",
    "    print(phi(inter_layer[0]['soma']).shape,hat_inter_layer[0]['basal'].shape,hidden_layer[0]['basal'].shape)\n",
    "    weights_IP[0] += eta_IP[0]*((phi(inter_layer[0]['soma']) - phi(hat_inter_layer[0]['basal']))*(hidden_layer[0]['basal']))\n",
    "    hat_inter_layer[1]['basal'] = (gD/(gLK + gD))*(inter_layer[1]['basal'])\n",
    "    weights_IP[1] += eta_IP[1]*((phi(inter_layer[1]['soma']) - phi(hat_inter_layer[1]['basal']))*(hidden_layer[1]['basal']))\n",
    "    \n",
    "    #pyramid to inter synaptic weight\n",
    "    eta_PI[0] = 0.0005\n",
    "    eta_PI[1] = 0.0005\n",
    "    weights_PI[0] += eta_PI[0]*((np.full((500,1),V_rest) - hidden_layer[0]['apical'])*(inter_layer[0]['basal']))\n",
    "    weights_PI[1] += eta_PI[1]*((np.full((500,1),V_rest) - hidden_layer[1]['apical'])*(inter_layer[1]['basal']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def teacher_current(predicted_current,E_inh, E_exc, g_som=0.8):\n",
    "#     gp_exc = g_som*((predicted_current-E_inh)/(E_exc-E_inh))\n",
    "#     gp_inh = -g_som*((predicted_current-E_exc)/(E_exc-E_inh))\n",
    "#     return (gp_exc*(E_exc-predicted_current) + gp_inh*(E_inh-predicted_current))\n",
    "def teacher_current(predicted_current,target, g_som=0.8):\n",
    "    return g_som*(target-predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = {}\n",
    "input_layer['basal'] = np.zeros((784,1))\n",
    "input_layer['soma'] = np.zeros((784,1))\n",
    "\n",
    "hidden_layer = {}\n",
    "num_of_hidden_layers = 2\n",
    "for i in range(num_of_hidden_layers):\n",
    "    hidden_layer[i] = {}\n",
    "    hidden_layer[i]['basal'] = np.zeros((500,1))\n",
    "    hidden_layer[i]['soma'] = np.zeros((500,1))\n",
    "    hidden_layer[i]['apical'] = np.zeros((500,1))\n",
    "\n",
    "inter_layer = {}\n",
    "for i in range(num_of_hidden_layers):\n",
    "    inter_layer[i] = {}\n",
    "    inter_layer[i]['basal'] = np.zeros((500,1))\n",
    "    inter_layer[i]['soma'] = np.zeros((500,1))\n",
    "    \n",
    "output_layer = {}\n",
    "output_layer['basal'] = np.zeros((10,1))\n",
    "output_layer['soma'] = np.zeros((10,1))\n",
    "\n",
    "weights_PP = {}\n",
    "weights_PP[0] = np.random.uniform(-0.1,0.1,392000).reshape(500,784)\n",
    "weights_PP[1] = np.random.uniform(-0.1,0.1,250000).reshape(500,500)\n",
    "weights_PP[2] = np.random.uniform(-0.1,0.1,5000).reshape(10,500)\n",
    "\n",
    "weights_PI = {}\n",
    "weights_PI[0] = np.random.uniform(-1,1,500).reshape(500,1)\n",
    "weights_PI[1] = np.random.uniform(-1,1,500).reshape(500,1)\n",
    "\n",
    "weights_IP = {}\n",
    "weights_IP[0] = np.random.uniform(-1,1,500).reshape(500,1)\n",
    "weights_IP[1] = np.random.uniform(-1,1,500).reshape(500,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('binarized_mnist_data.pkl','rb')\n",
    "data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in,train_out,test_in,test_out = data['train_input'],data['train_output'],data['test_input'],data['test_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in = mnist_to_current(train_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer['soma'] = train_in[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mandh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "change_mp(0,hidden_layer[1]['soma'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_layer[0]['soma'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to include weak nudge?\n",
    "# change_mp(1,output_layer['soma'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "(output_layer['basal']) = np.transpose(np.matmul(np.transpose(hidden_layer[1]['soma']),np.transpose(weights_PP[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what are the values of E_inh E_exc?\n",
    "predicted = np.asarray([2 if i==0 else 12 for i in train_out[0]])\n",
    "weak_nudge = teacher_current(predicted,output_layer['basal'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.6 -1.6 -1.6 -1.6 -1.6 -9.6 -1.6 -1.6 -1.6 -1.6]\n",
      " [-1.6 -1.6 -1.6 -1.6 -1.6 -9.6 -1.6 -1.6 -1.6 -1.6]\n",
      " [-1.6 -1.6 -1.6 -1.6 -1.6 -9.6 -1.6 -1.6 -1.6 -1.6]\n",
      " [-1.6 -1.6 -1.6 -1.6 -1.6 -9.6 -1.6 -1.6 -1.6 -1.6]\n",
      " [-1.6 -1.6 -1.6 -1.6 -1.6 -9.6 -1.6 -1.6 -1.6 -1.6]\n",
      " [-1.6 -1.6 -1.6 -1.6 -1.6 -9.6 -1.6 -1.6 -1.6 -1.6]\n",
      " [-1.6 -1.6 -1.6 -1.6 -1.6 -9.6 -1.6 -1.6 -1.6 -1.6]\n",
      " [-1.6 -1.6 -1.6 -1.6 -1.6 -9.6 -1.6 -1.6 -1.6 -1.6]\n",
      " [-1.6 -1.6 -1.6 -1.6 -1.6 -9.6 -1.6 -1.6 -1.6 -1.6]\n",
      " [-1.6 -1.6 -1.6 -1.6 -1.6 -9.6 -1.6 -1.6 -1.6 -1.6]]\n"
     ]
    }
   ],
   "source": [
    "print(weak_nudge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 1) (500, 1) (500, 1)\n"
     ]
    }
   ],
   "source": [
    "#what is V_rest?\n",
    "update_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
